{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## BERT ##########\n",
    "\n",
    "!pip install transformers datasets evaluate accelerate -q #Installs everything we might need\n",
    "from google.colab import drive\n",
    "print(\"Starting...\")\n",
    "drive.mount('/content/drive')\n",
    "print(\"Drive mounted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14911d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "CSV_PATH = \"/content/drive/MyDrive/CS Projects/Winter Project 2526/Data/raw/bbc_data.csv\" #Sets the path to the CSV file\n",
    "\n",
    "if os.path.exists(CSV_PATH):\n",
    "    df = pd.read_csv(CSV_PATH) #Checks and loads the CSV file\n",
    "    df = df.rename(columns={'data': 'text', 'labels': 'label_name'}) #Renames the columns\n",
    "\n",
    "    print(f\"Total documents loaded: {len(df)}\")\n",
    "    print(\"\\nFirst 5 rows (Check names!):\")\n",
    "    print(df.head())\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(df['label_name'].value_counts())\n",
    "else:\n",
    "    print(f\"ERROR: CSV file not found at: {CSV_PATH}\")\n",
    "    print(\"Please check your Google Drive path and file name.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d181c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased') #Loads the tokenizer\n",
    "\n",
    "if 'df' in globals() and not df.empty: #Tests on the first sample text from the dataframe\n",
    "    sample_text = df['text'].iloc[0]\n",
    "\n",
    "    tokenized_output = tokenizer(sample_text,\n",
    "                                 padding=True,\n",
    "                                 truncation=True)\n",
    "\n",
    "    print(\"\\n--- Tokenizer Check Successful ---\")\n",
    "    print(\"Sample Text:\", sample_text)\n",
    "    print(\"Input IDs:\", tokenized_output['input_ids'][:10])\n",
    "else:\n",
    "    print(\"DataFrame 'df' not found or is empty. Cannot test tokenizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = df['label_name'].unique().tolist() #Shows every text category\n",
    "print(f\"Original Unique Labels: {unique_labels}\")\n",
    "\n",
    "label_map = {label: i for i, label in enumerate(unique_labels)} #Creates a mapping between labels and integers\n",
    "id_to_label = {i: label for i, label in enumerate(unique_labels)} #Creates a reverse mapping between integers and labels\n",
    "\n",
    "print(f\"Created Label-to-ID Mapping: {label_map}\")\n",
    "\n",
    "df['label'] = df['label_name'].map(label_map) #Applies the mapping to the dataframe\n",
    "\n",
    "print(\"\\nVerification of New Labels:\") #Verifies the labels\n",
    "print(df[['label_name', 'label']].head())\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "hf_dataset = Dataset.from_pandas(df, preserve_index=False) #Converts Pandas dataframe to Hugging Face Dataset\n",
    "\n",
    "\n",
    "train_test_split = hf_dataset.train_test_split(test_size=0.2, seed=42) #Splits the dataset. 80% for training, 20% for testing/validation\n",
    "\n",
    "test_valid_split = train_test_split['test'].train_test_split(test_size=0.5, seed=42) #Splits the 20% set into 10% validation and 10% test\n",
    "\n",
    "dataset_dict = DatasetDict({ #Combines the splits into a DatasetDict object\n",
    "    'train': train_test_split['train'],\n",
    "    'validation': test_valid_split['train'],\n",
    "    'test': test_valid_split['test']\n",
    "})\n",
    "\n",
    "print(\"\\n--- Dataset Split Information ---\")\n",
    "print(dataset_dict)\n",
    "print(f\"Train samples: {len(dataset_dict['train'])}\")\n",
    "print(f\"Validation samples: {len(dataset_dict['validation'])}\")\n",
    "print(f\"Test samples: {len(dataset_dict['test'])}\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased') #Loads the tokenizer\n",
    "\n",
    "def tokenize_function(examples): #Function to apply tokenization to several examples\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length')\n",
    "\n",
    "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True) #Applies the function to the entire DatasetDict\n",
    "\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['text', 'label_name']) #Removes the original, now unnecessary columns\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\") #Renames the label column to 'labels'\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\") #Sets the format to PyTorch tensors\n",
    "\n",
    "print(\"\\n--- Final Tokenized Dataset (Ready for Training) ---\")\n",
    "print(tokenized_datasets)\n",
    "print(tokenized_datasets['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf61cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred): #Defines evaluation metrics\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    preds = np.argmax(predictions, axis=-1) #Converts logits to predicted class IDs\n",
    "\n",
    "    f1 = f1_score(labels, preds, average='weighted') #Calculates the weighted F1 score, as well as the accuracy\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1_weighted': f1,\n",
    "    }\n",
    "\n",
    "num_labels = 5 #Initializes the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments( #Training configuration\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    #Memory optimization\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "\n",
    "    dataloader_num_workers=4, #Uses 4 CPU cores to prepare the next batch in parallel, making it faster\n",
    "\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    report_to='none',\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_weighted',\n",
    "    greater_is_better=True,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True #Enables faster training on the T4 GPU\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer( #Trainer Initialization\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nStarting Fine-Tuning on T4 GPU...\")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "model_dir = \"/content/drive/MyDrive/CS Projects/Winter Project 2526/Models/Bert Model\" #Saves the final best model\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "trainer.save_model(model_dir)\n",
    "print(f\"\\nBERT Model saved to Drive at: {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LOGISTIC REGRESSION ##########\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "train_texts = [item['text'] for item in dataset_dict['train']] #Prepares the data\n",
    "test_texts = [item['text'] for item in dataset_dict['test']]\n",
    "train_labels = [item['label'] for item in dataset_dict['train']]\n",
    "test_labels = [item['label'] for item in dataset_dict['test']]\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000) #Vectorization\n",
    "X_train_tfidf = vectorizer.fit_transform(train_texts)\n",
    "X_test_tfidf = vectorizer.transform(test_texts)\n",
    "\n",
    "simple_model = LogisticRegression(max_iter=1000) #Trains the model\n",
    "simple_model.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "\n",
    "simple_preds = simple_model.predict(X_test_tfidf) #Evaluates the model\n",
    "simple_acc = accuracy_score(test_labels, simple_preds)\n",
    "simple_mcc = matthews_corrcoef(test_labels, simple_preds)\n",
    "\n",
    "print(f\"Results for Logistic Regression Model:\")\n",
    "print(f\"Accuracy: {simple_acc:.4f}\")\n",
    "print(f\"MCC: {simple_mcc:.4f}\\n\")\n",
    "print(classification_report(test_labels, simple_preds))\n",
    "\n",
    "model_dir = '/content/drive/MyDrive/CS Projects/Winter Project 2526/Models/LogReg/' #Saves to Google Drive\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "joblib.dump(simple_model, os.path.join(model_dir, 'logreg_model.pkl'))\n",
    "joblib.dump(vectorizer, os.path.join(model_dir, 'tfidf_vectorizer.pkl'))\n",
    "\n",
    "print(f\"\\nLogistic Regression Model saved to Drive at: {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LSTM ##########\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "max_words = 10000 #Prepares the data\n",
    "max_len = 200 #Each article only gets 200 words\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(train_texts), maxlen=max_len)\n",
    "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(test_texts), maxlen=max_len)\n",
    "\n",
    "\n",
    "model_lstm = Sequential([ #Builds the LSTM model architecture\n",
    "    Embedding(max_words, 128, input_length=max_len),\n",
    "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"Training the LSTM...\") #Trains the model\n",
    "model_lstm.fit(X_train_seq, np.array(train_labels), epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "lstm_loss, lstm_acc = model_lstm.evaluate(X_test_seq, np.array(test_labels)) #Evaluates the model\n",
    "print(f\"LSTM Accuracy: {lstm_acc:.4f}\")\n",
    "\n",
    "model_lstm.save('my_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f457405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import os\n",
    "\n",
    "raw_preds = model_lstm.predict(X_test_seq) #Converts the probaibilities into class predictions\n",
    "lstm_preds = np.argmax(raw_preds, axis=1)\n",
    "\n",
    "lstm_acc = accuracy_score(test_labels, lstm_preds) #Calculates accuracy and MCC\n",
    "lstm_mcc = matthews_corrcoef(test_labels, lstm_preds)\n",
    "\n",
    "print(f\"\\nResults for LSTM Model:\") #Results\n",
    "print(f\"Accuracy: {lstm_acc:.4f}\")\n",
    "print(f\"MCC: {lstm_mcc:.4f}\")\n",
    "\n",
    "model_dir = \"/content/drive/MyDrive/CS Projects/Winter Project 2526/Models/LSTM/\"\n",
    "\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "\n",
    "\n",
    "file_dir = \"/content/drive/MyDrive/CS Projects/Winter Project 2526/Models/LSTM/lstm_model.keras\" #Saves the model to Google Drive\n",
    "\n",
    "\n",
    "\n",
    "model_lstm.save(file_dir)\n",
    "print(f\"\\nLSTM Model saved to Drive at: {file_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
